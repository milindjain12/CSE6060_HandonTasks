{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Digital Assignment 1</h1>\n",
    "<h4 style=\"text-align:center\">(Milind Jain - 19MAI0046)</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TextBlob</h1>\n",
    "<p>TextBlob is a python library which is very popular among the beginners in NLP as it provides very simple implementations of extracting Tokens, part-of-speech tags, sentimental analysis of a document, lemmatization, noun phrases etc.\n",
    "This library is quite popular after NLTK as it is quite simple to use.</p>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from textblob.wordnet import VERB\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Sentences ####\n",
      "[Sentence(\"High Explosive Research was the independent British project to develop atomic bombs after the Second World War.\"), Sentence(\"The decision to undertake it was made in 1947 and publicly announced in 1948.\"), Sentence(\"The project was a civil, not a military, one.\"), Sentence(\"Production facilities were constructed under the direction of Christopher Hinton,\n",
      "including a uranium metal plant at Springfields, nuclear reactors and a plutonium processing plant at Windscale,\n",
      "and a gaseous diffusion uranium enrichment facility at Capenhurst, near Chester.\")]\n",
      "\n",
      "##### Tokenized Words####\n",
      "['High', 'Explosive', 'Research', 'was', 'the', 'independent', 'British', 'project', 'to', 'develop', 'atomic', 'bombs', 'after', 'the', 'Second', 'World', 'War', 'The', 'decision', 'to', 'undertake', 'it', 'was', 'made', 'in', '1947', 'and', 'publicly', 'announced', 'in', '1948', 'The', 'project', 'was', 'a', 'civil', 'not', 'a', 'military', 'one', 'Production', 'facilities', 'were', 'constructed', 'under', 'the', 'direction', 'of', 'Christopher', 'Hinton', 'including', 'a', 'uranium', 'metal', 'plant', 'at', 'Springfields', 'nuclear', 'reactors', 'and', 'a', 'plutonium', 'processing', 'plant', 'at', 'Windscale', 'and', 'a', 'gaseous', 'diffusion', 'uranium', 'enrichment', 'facility', 'at', 'Capenhurst', 'near', 'Chester']\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('''High Explosive Research was the independent British project to develop atomic bombs after the Second World War. \n",
    "The decision to undertake it was made in 1947 and publicly announced in 1948. The project was a civil, not a military, one. \n",
    "Production facilities were constructed under the direction of Christopher Hinton,\n",
    "including a uranium metal plant at Springfields, nuclear reactors and a plutonium processing plant at Windscale,\n",
    "and a gaseous diffusion uranium enrichment facility at Capenhurst, near Chester.''')\n",
    "\n",
    "print(\"\\n##### Sentences ####\")\n",
    "print(blob.sentences)\n",
    "\n",
    "tokenised_words = []\n",
    "## printing words of first sentence\n",
    "for sentence in blob.sentences:\n",
    "    for word in sentence.words:\n",
    "        tokenised_words.append(word)\n",
    "        \n",
    "print(\"\\n##### Tokenized Words####\")\n",
    "print(tokenised_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>As the above code suggest only using the <b>TextBlob()</b> method is enough for tokenizing a document in sentences and indivisual words.</li>\n",
    "<li>In the tokenized words I observed that it doesn't consider punctuations as tokens as the output shows it.</li>\n",
    "<li>It is a quite easy process for extracting tokens and quite easy for begineers.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explosive', 'independent british project', 'atomic bombs', 'world war', 'production', 'christopher hinton', 'uranium metal plant', 'springfields', 'nuclear reactors', 'plutonium processing plant', 'windscale', 'gaseous diffusion uranium enrichment facility', 'capenhurst', 'chester']\n"
     ]
    }
   ],
   "source": [
    "noun_phrases = []\n",
    "for np in blob.noun_phrases:\n",
    "    noun_phrases.append(np)\n",
    "    \n",
    "print(noun_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>Using Text Blob we can extract all the noun phrases in the document like in above output</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('High', 'JJ'), ('Explosive', 'NNP'), ('Research', 'NNP'), ('was', 'VBD'), ('the', 'DT'), ('independent', 'JJ'), ('British', 'JJ'), ('project', 'NN'), ('to', 'TO'), ('develop', 'VB'), ('atomic', 'JJ'), ('bombs', 'NNS'), ('after', 'IN'), ('the', 'DT'), ('Second', 'JJ'), ('World', 'NNP'), ('War', 'NNP'), ('The', 'DT'), ('decision', 'NN'), ('to', 'TO'), ('undertake', 'VB'), ('it', 'PRP'), ('was', 'VBD'), ('made', 'VBN'), ('in', 'IN'), ('1947', 'CD'), ('and', 'CC'), ('publicly', 'RB'), ('announced', 'VBN'), ('in', 'IN'), ('1948', 'CD'), ('The', 'DT'), ('project', 'NN'), ('was', 'VBD'), ('a', 'DT'), ('civil', 'JJ'), ('not', 'RB'), ('a', 'DT'), ('military', 'JJ'), ('one', 'CD'), ('Production', 'NN'), ('facilities', 'NNS'), ('were', 'VBD'), ('constructed', 'VBN'), ('under', 'IN'), ('the', 'DT'), ('direction', 'NN'), ('of', 'IN'), ('Christopher', 'NNP'), ('Hinton', 'NNP'), ('including', 'VBG'), ('a', 'DT'), ('uranium', 'JJ'), ('metal', 'NN'), ('plant', 'NN'), ('at', 'IN'), ('Springfields', 'NNP'), ('nuclear', 'JJ'), ('reactors', 'NNS'), ('and', 'CC'), ('a', 'DT'), ('plutonium', 'NN'), ('processing', 'NN'), ('plant', 'NN'), ('at', 'IN'), ('Windscale', 'NNP'), ('and', 'CC'), ('a', 'DT'), ('gaseous', 'JJ'), ('diffusion', 'NN'), ('uranium', 'NN'), ('enrichment', 'NN'), ('facility', 'NN'), ('at', 'IN'), ('Capenhurst', 'NNP'), ('near', 'IN'), ('Chester', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagging = []\n",
    "for word, tag in blob.tags:\n",
    "    pos_tagging.append((word, tag))\n",
    "    \n",
    "print(pos_tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>We also performed part of speech tagging but text blob is quite simple and it is perfect for the begineers</li>\n",
    "<li>TextBlob also follows Penn Treebank Tags just as nltk library.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Word Inflection and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: decision\n",
      "Singular Word: decision\n",
      "Plural Word: decisions\n"
     ]
    }
   ],
   "source": [
    "# Word Inflection\n",
    "print (\"Word: \"+blob.sentences[1].words[1])\n",
    "print (\"Singular Word: \" + blob.sentences[1].words[1].singularize())\n",
    "print (\"Plural Word: \" + blob.sentences[1].words[1].pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>TextBlob provides us with a functionality of doing word inflection i.e. we can get plural and singular forms of a word using <b>singularize()</b> and <b>pluralize()</b> methods.</li>\n",
    "<li>NLTK does not provide this feature.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High', 'Explosive', 'Research', 'wa', 'the', 'independent', 'British', 'project', 'to', 'develop', 'atomic', 'bomb', 'after', 'the', 'Second', 'World', 'War', 'The', 'decision', 'to', 'undertake', 'it', 'wa', 'made', 'in', '1947', 'and', 'publicly', 'announced', 'in', '1948', 'The', 'project', 'wa', 'a', 'civil', 'not', 'a', 'military', 'one', 'Production', 'facility', 'were', 'constructed', 'under', 'the', 'direction', 'of', 'Christopher', 'Hinton', 'including', 'a', 'uranium', 'metal', 'plant', 'at', 'Springfields', 'nuclear', 'reactor', 'and', 'a', 'plutonium', 'processing', 'plant', 'at', 'Windscale', 'and', 'a', 'gaseous', 'diffusion', 'uranium', 'enrichment', 'facility', 'at', 'Capenhurst', 'near', 'Chester']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemma_words = []\n",
    "for word, tag in blob.tags:\n",
    "    lemma_words.append(word.lemmatize())\n",
    "    \n",
    "print(lemma_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>TextBlob uses WordNet Lemmatizer for lemmatizing.</li>\n",
    "<li>Lemmatized words of a token can be extracted from the <b>Word</b> Object</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('High', 'Explosive'), ('Explosive', 'Research'), ('Research', 'was'), ('was', 'the'), ('the', 'independent'), ('independent', 'British'), ('British', 'project'), ('project', 'to'), ('to', 'develop'), ('develop', 'atomic'), ('atomic', 'bombs'), ('bombs', 'after'), ('after', 'the'), ('the', 'Second'), ('Second', 'World'), ('World', 'War'), ('War', 'The'), ('The', 'decision'), ('decision', 'to'), ('to', 'undertake'), ('undertake', 'it'), ('it', 'was'), ('was', 'made'), ('made', 'in'), ('in', '1947'), ('1947', 'and'), ('and', 'publicly'), ('publicly', 'announced'), ('announced', 'in'), ('in', '1948'), ('1948', 'The'), ('The', 'project'), ('project', 'was'), ('was', 'a'), ('a', 'civil'), ('civil', 'not'), ('not', 'a'), ('a', 'military'), ('military', 'one'), ('one', 'Production'), ('Production', 'facilities'), ('facilities', 'were'), ('were', 'constructed'), ('constructed', 'under'), ('under', 'the'), ('the', 'direction'), ('direction', 'of'), ('of', 'Christopher'), ('Christopher', 'Hinton'), ('Hinton', 'including'), ('including', 'a'), ('a', 'uranium'), ('uranium', 'metal'), ('metal', 'plant'), ('plant', 'at'), ('at', 'Springfields'), ('Springfields', 'nuclear'), ('nuclear', 'reactors'), ('reactors', 'and'), ('and', 'a'), ('a', 'plutonium'), ('plutonium', 'processing'), ('processing', 'plant'), ('plant', 'at'), ('at', 'Windscale'), ('Windscale', 'and'), ('and', 'a'), ('a', 'gaseous'), ('gaseous', 'diffusion'), ('diffusion', 'uranium'), ('uranium', 'enrichment'), ('enrichment', 'facility'), ('facility', 'at'), ('at', 'Capenhurst'), ('Capenhurst', 'near'), ('near', 'Chester')]\n"
     ]
    }
   ],
   "source": [
    "# bigrams\n",
    "ngrams = []\n",
    "for ngram in blob.ngrams(2):\n",
    "    ngrams.append((ngram[0], ngram[1]))\n",
    "    \n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>We can also extract ngrams from the blob object by specifying the number.</li>\n",
    "<li>In above example I extracted bigrams from the blob object based on the document.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Explosive Research was the independent British project to develop atomic bombs after the Second World War. \n",
      "The decision to undertake it was made in 1947 and publicly announced in 1948. The project was a civil, not a military, one. \n",
      "Production facilities were constructed under the direction of Christopher Hinton,\n",
      "including a uranium metal plant at Springfields, nuclear reactors and a plutonium processing plant at Windscale,\n",
      "and a gaseous diffusion uranium enrichment facility at Capenhurst, near Chester.\n",
      "\n",
      "#####Sentiment#####\n",
      "Sentiment(polarity=0.044285714285714296, subjectivity=0.17595238095238092)\n",
      "\n",
      "#####Sentiment Assessments#####\n",
      "Sentiment(polarity=0.044285714285714296, subjectivity=0.17595238095238092, assessments=[(['high'], 0.16, 0.5399999999999999, None), (['independent'], 0.0, 0.125, None), (['british'], 0.0, 0.0, None), (['second'], 0.0, 0.0, None), (['publicly'], 0.0, 0.06666666666666667, None), (['not', 'military'], 0.05, 0.1, None), (['near'], 0.1, 0.4, None)])\n"
     ]
    }
   ],
   "source": [
    "print(blob)\n",
    "print(\"\\n#####Sentiment#####\")\n",
    "print(blob.sentiment)\n",
    "print(\"\\n#####Sentiment Assessments#####\")\n",
    "print(blob.sentiment_assessments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>TextBlob also gives us the a feature to extract sentiment based on the document.</li>\n",
    "<li>It provides 3 measures i.e., <b>Subjectivity</b>, <b>Polarity</b> and <b>Assessments</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) WordNet Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('happy.a.01'), Synset('felicitous.s.02'), Synset('glad.s.02'), Synset('happy.s.04')]\n",
      "\n",
      "\n",
      "[Synset('play.v.01'), Synset('play.v.02'), Synset('play.v.03'), Synset('act.v.03'), Synset('play.v.05'), Synset('play.v.06'), Synset('play.v.07'), Synset('act.v.05'), Synset('play.v.09'), Synset('play.v.10'), Synset('play.v.11'), Synset('play.v.12'), Synset('play.v.13'), Synset('play.v.14'), Synset('play.v.15'), Synset('play.v.16'), Synset('play.v.17'), Synset('play.v.18'), Synset('toy.v.02'), Synset('play.v.20'), Synset('dally.v.04'), Synset('play.v.22'), Synset('dally.v.01'), Synset('play.v.24'), Synset('act.v.10'), Synset('play.v.26'), Synset('bring.v.03'), Synset('play.v.28'), Synset('play.v.29'), Synset('bet.v.02'), Synset('play.v.31'), Synset('play.v.32'), Synset('play.v.33'), Synset('meet.v.10'), Synset('play.v.35')]\n"
     ]
    }
   ],
   "source": [
    "word = Word(\"Happy\")\n",
    "print(word.synsets)\n",
    "print(\"\\n\")\n",
    "print(Word(\"Play\").get_synsets(pos=VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "<li>We can extract word synonyms using the Word object which used WordNet Integration.</li>\n",
    "<li>We can also extract synonyms on the basis of part of speech tag as in in above example I extracted all the synonyms realted to play when used as verb.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusion</h1>\n",
    "<p>This Hands On experience with TextBlob has given me an another alternative for NLP and its quite easy and quick to implement. Its really a begineer's library.</p>\n",
    "<p>Compared to NLTK library flexibility is less and options for different features required for NLP are less.</p>\n",
    "<p>GIT Repo Link :- </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>References</h1>\n",
    "<p>[1] https://textblob.readthedocs.io/en/dev/index.html</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
